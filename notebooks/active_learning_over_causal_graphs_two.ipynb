{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using structure one from coenen et al. (2015)\n",
    "# prior over causal graphs\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from fractions import Fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hyp = 2\n",
    "prior = [Fraction(1, n_hyp) for _ in range(n_hyp)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calculate prior entropy over graphs: $H(G) = \\sum_{g \\in G} P(g) \\log_2 \\frac{1}{P(g)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "prior_entropy = Fraction(sum([p * math.log(1/p, 2) for p in prior]))\n",
    "print(prior_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calculate information gain based on a particular action and observed outcome: $$IG(a, o) = H(G) - H(G|a, o)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calculate expected information gain for a particular action (averaging over all possible outcomes for that action): $$EIG(a) = H(G) - \\sum_{o \\in O} p(o|a)H(G|a, o)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calculate posterior entropy: $$H(G|a, o) = \\sum_{g \\in G} p(g|a, o) \\log_2 \\frac{1}{P(g|a, o)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where $P(g|a, o)$ can be calculated using Bayes' rule as: $P(o|g, a)P(g)/P(o|a)$ and $P(o|a)$ by marginalizing over all graphs and their likelihood of producing outcome $o$ from action $a$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = np.array([[0, 0, 0], [1, 0, 1], [0, 0, 0]])\n",
    "np.flatnonzero(edges[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class DirectedGraph:\n",
    "    def __init__(self, edges, transmission_rate=0.8, background_rate=0.05):\n",
    "        self.adjacency_matrix = edges\n",
    "        self.n = self.adjacency_matrix.shape[0]\n",
    "        self.transmission_rate = transmission_rate\n",
    "        self.background_rate = background_rate\n",
    "        \n",
    "        # TODO: add check to see if graph is not cyclic\n",
    "        assert self.n >= 0\n",
    "        assert self.transmission_rate >= 0.0\n",
    "        \n",
    "    def get_parents(self, node):\n",
    "        \"\"\"Calculate the parents of a given node\"\"\"\n",
    "        return np.flatnonzero(self.adjacency_matrix[:, node])\n",
    "        \n",
    "    def get_children(self, node):\n",
    "        \"\"\"Calculate the children of a given node\"\"\"\n",
    "        return np.flatnonzero(self.adjacency_matrix[node])\n",
    "        \n",
    "    def intervene(self, node):\n",
    "        \"\"\"Calculate the outcome from intervening on a particular node\"\"\"\n",
    "        \n",
    "        outcomes = np.zeros(self.n)  # array to store outcomes\n",
    "        outcomes[node] = 1.0  # set intervened node to be on\n",
    "        \n",
    "        # temporarily remove edge between node and parent\n",
    "        intervened_parents = self.get_parents(node) \n",
    "        self.adjacency_matrix[intervened_parents, node] = 0\n",
    "\n",
    "        q = deque()  # create queue to store nodes\n",
    "        \n",
    "        # set root nodes to be bg rate and add to queue\n",
    "        # root notes have no parents and are not the node intervened on\n",
    "        for i in range(self.n):\n",
    "            if len(self.get_parents(i)) == 0 and i != node:\n",
    "                outcomes[i] = self.background_rate\n",
    "                q.append(i)\n",
    "        \n",
    "        # append children of intervened node to queue\n",
    "        children = self.get_children(node)\n",
    "        q.append(children)  # append children of nodes to queue\n",
    "        \n",
    "        while len(q) is not 0:\n",
    "            curr_node = q.popleft()  # remove first node from queue\n",
    "            \n",
    "            # calculate probability of turning on\n",
    "            parents = self.get_parents(curr_node)\n",
    "            outcomes[curr_node] = np.sum(outcomes[parents]) * \\\n",
    "                self.transmission_rate + self.background_rate\n",
    "            \n",
    "            # append children to queue\n",
    "            children = self.get_children(curr_node)\n",
    "            for child in children:\n",
    "                q.append(child) \n",
    "        \n",
    "        # add edges back in from parents to intervened node\n",
    "        self.adjacency_matrix[intervened_parents, node] = 1\n",
    "\n",
    "        # set any outcomes greater than 1 to 1\n",
    "        outcomes[outcomes > 1.0] = 1.0\n",
    "        \n",
    "        return outcomes\n",
    "        \n",
    "    def likelihood(self):\n",
    "        \"\"\"Calculate the likelihood of a node being turned on?\"\"\"\n",
    "        lik = np.zeros((self.n, self.n))\n",
    "        for i in range(self.n):\n",
    "            lik[i] = self.intervene(i)\n",
    "            \n",
    "        return lik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActiveGraphLearner:\n",
    "    def __init__(self, graphs):\n",
    "        self.n_hyp = len(graphs)\n",
    "        self.actions = 3\n",
    "        self.outcomes = 3\n",
    "        self.hyp = graphs\n",
    "        self.prior = 1 / self.n_hyp * np.ones((self.actions, self.outcomes))\n",
    "        \n",
    "    def likelihood(self):\n",
    "        \"\"\"Returns the likelihood of each action/outcome pair for each graph\"\"\"\n",
    "        lik = np.array([h.likelihood() for h in self.hyp])\n",
    "        return lik\n",
    "    \n",
    "    def update_posterior(self):\n",
    "        \"\"\"Calculates the posterior over all possible action/outcome pairs\n",
    "        for each graph\"\"\"\n",
    "        post = self.prior * self.likelihood()\n",
    "        self.posterior = np.nan_to_num(post / np.sum(post, axis=0))\n",
    "        \n",
    "    def prior_entropy(self):\n",
    "        pass\n",
    "        \n",
    "    def posterior_entropy(self):\n",
    "        return np.nansum(self.posterior * np.log2(1 / self.posterior), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appending 1\n",
      "appending 2\n",
      "appending 2\n",
      "appending 1\n",
      "[[ 1.    0.05  0.05]\n",
      " [ 1.    1.    0.05]\n",
      " [ 1.    0.05  1.  ]]\n",
      "[[0 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "edges_1 = np.array([[0, 0, 0], [1, 0, 1], [0, 0, 0]])  # common cause\n",
    "edges_2 = np.array([[0, 1, 1], [0, 0, 0], [0, 0, 0]])  # common cause\n",
    "dg1 = DirectedGraph(common_effect_1, transmission_rate=1.0, background_rate=0.05)\n",
    "# dg2 = DirectedGraph(edges_2, transmission_rate=0.8, background_rate=0.05)\n",
    "print(dg1.likelihood())\n",
    "print(dg1.adjacency_matrix)\n",
    "# graphs = [dg1, dg2]\n",
    "# agl = ActiveGraphLearner(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:18: RuntimeWarning: invalid value encountered in true_divide\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:24: RuntimeWarning: divide by zero encountered in true_divide\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:24: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    }
   ],
   "source": [
    "agl.update_posterior()\n",
    "post = agl.posterior\n",
    "eig = np.sum(post, axis=0) * agl.posterior_entropy()\n",
    "print(eig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 0.,  0.,  1.]])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(post, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enumerate all graphs\n",
    "common_cause_1 = np.array([[0, 1, 1], [0, 0, 0], [0, 0, 0]])\n",
    "common_cause_2 = np.array([[0, 0, 0], [1, 0, 1], [0, 0, 0]])\n",
    "common_cause_3 = np.array([[0, 0, 0], [0, 0, 0], [1, 1, 0]])\n",
    "common_effect_1 = np.array([[0, 0, 1], [0, 0, 1], [0, 0, 0]])\n",
    "common_effect_2 = np.array([[0, 1, 0], [0, 0, 0], [0, 1, 0]])\n",
    "common_effect_3 = np.array([[0, 0, 0], [1, 0, 0], [1, 0, 0]])\n",
    "causal_chain_1 = np.array([[0, 1, 0], [0, 0, 1], [0, 0, 0]])\n",
    "causal_chain_2 = np.array([[0, 0, 0], [1, 0, 0], [0, 1, 0]])\n",
    "causal_chain_3 = np.array([[0, 0, 1], [1, 0, 0], [0, 0, 0]])\n",
    "causal_chain_4 = np.array([[0, 0, 0], [0, 0, 1], [1, 0, 0]])\n",
    "causal_chain_5 = np.array([[0, 1, 0], [0, 0, 0], [1, 0, 0]])\n",
    "causal_chain_6 = np.array([[0, 0, 1], [0, 0, 0], [0, 1, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True], dtype=bool)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = np.zeros(3, dtype='bool')\n",
    "foo[2] = True\n",
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
